# file: streamlit_app/app.py
import streamlit as st
import pandas as pd
import requests
import io
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import os
import json


# Set up the page configuration
st.set_page_config(
    page_title="Sales Forecasting App",
    page_icon="üìä",
    layout="wide"
)

# Title
st.title("üìä Sales Forecasting App")

# Initialize session state
if 'uploaded_file_path' not in st.session_state:
    st.session_state.uploaded_file_path = None
if 'preprocessed_shop_csv' not in st.session_state:
    st.session_state.preprocessed_shop_csv = None
if 'preprocessed_category_csv' not in st.session_state:
    st.session_state.preprocessed_category_csv = None
if 'preprocessing_stats' not in st.session_state:
    st.session_state.preprocessing_stats = None
if 'trained_model_path' not in st.session_state:
    st.session_state.trained_model_path = None
if 'training_metrics' not in st.session_state:
    st.session_state.training_metrics = None
if 'forecast_data' not in st.session_state:
    st.session_state.forecast_data = None
if 'forecast_csv_path' not in st.session_state:
    st.session_state.forecast_csv_path = None
if 'cv_results' not in st.session_state:
    st.session_state.cv_results = None
if 'pdf_data' not in st.session_state:
    st.session_state.pdf_data = None
if 'pdf_filename' not in st.session_state:
    st.session_state.pdf_filename = None
if 'log_transform_used' not in st.session_state:
    st.session_state.log_transform_used = False
if 'diagnostics' not in st.session_state:
    st.session_state.diagnostics = None
if 'model_comparison' not in st.session_state:
    st.session_state.model_comparison = None

# FastAPI backend URL
FASTAPI_URL = os.getenv("FASTAPI_URL", "http://localhost:8888")

# Sidebar: Health check
with st.sidebar:
    st.header("API Status")
    try:
        health_response = requests.get(f"{FASTAPI_URL}/health", timeout=5)
        if health_response.status_code == 200:
            st.success("‚úÖ Backend API is running")
        else:
            st.error("‚ùå Backend API is not responding")
    except:
        st.error("‚ùå Unable to connect to backend API")
    
    st.header("Help")
    with st.expander("About this app"):
        st.write("""
        This application allows you to:
        1. Upload sales data (CSV)
        2. Preprocess and validate data
        3. Train Prophet forecasting models
        4. Evaluate models with cross-validation
        5. Generate predictions
        6. Download reports as PDF
        """)

# File uploader
st.header("üìÅ Step 1: Upload Data")
uploaded_file = st.file_uploader("Upload your sales CSV file", type=["csv"], 
                                 help="CSV file must contain columns: Sale_Date, Product_ID, Product_Category, Unit_Price, Discount, Quantity_Sold")

if uploaded_file is not None:
    # Display raw data preview
    bytes_data = uploaded_file.getvalue()
    df_raw = pd.read_csv(io.StringIO(bytes_data.decode("utf-8")))
    
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("Raw Data Preview")
        st.dataframe(df_raw.head(10))
    
    with col2:
        st.subheader("Detected Columns")
        st.write(f"Columns: {', '.join(df_raw.columns.tolist())}")
        st.write(f"Total rows: {len(df_raw)}")
    
    # Upload file to backend
    if st.button("üì§ Upload to Backend", help="Uploads the CSV file to the backend API"):
        try:
            files = {"file": (uploaded_file.name, bytes_data, "text/csv")}
            response = requests.post(f"{FASTAPI_URL}/upload", files=files, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                st.session_state.uploaded_file_path = result["file_path"]
                st.success(f"‚úÖ File uploaded successfully: {result['file_path']}")
            else:
                st.error(f"‚ùå Upload failed: {response.text}")
        except Exception as e:
            st.error(f"‚ùå Error uploading file: {str(e)}")

# Preprocess section
st.header("‚öôÔ∏è Step 2: Preprocess Data")
if st.session_state.uploaded_file_path:
    col1, col2 = st.columns([3, 1])
    with col1:
        st.info(f"üìÑ File ready: {st.session_state.uploaded_file_path}")
    with col2:
        force_weekly = st.checkbox("Force weekly aggregation", 
                                  help="Force weekly aggregation regardless of data density")
    
    if st.button("üîÑ Preprocess Data", help="Preprocesses the uploaded CSV, validates data, and generates shop/category aggregates"):
        try:
            payload = {
                "file_path": st.session_state.uploaded_file_path,
                "force_weekly": force_weekly
            }
            response = requests.post(f"{FASTAPI_URL}/preprocess", json=payload, timeout=120)
            
            if response.status_code == 200:
                result = response.json()
                st.session_state.preprocessed_shop_csv = result["shop_csv"]
                st.session_state.preprocessed_category_csv = result["category_csv"]
                st.session_state.preprocessing_stats = result["stats"]
                
                st.success("‚úÖ Data preprocessed successfully!")
                
                # Show stats
                st.subheader("üìä Preprocessing Statistics")
                
                stats = result["stats"]
                agg_suggestion = result.get("aggregation_suggestion", {})
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Total Rows (Raw)", stats.get("n_rows_raw", "N/A"))
                    st.metric("Rows After Cleaning", stats.get("n_rows_clean", "N/A"))
                    st.metric("Unique Dates", stats.get("n_unique_dates", "N/A"))
                
                with col2:
                    st.metric("Date Range Start", stats.get("date_min", "N/A")[:10] if stats.get("date_min") else "N/A")
                    st.metric("Date Range End", stats.get("date_max", "N/A")[:10] if stats.get("date_max") else "N/A")
                    st.metric("Duplicates Removed", stats.get("duplicates_removed", 0))
                
                with col3:
                    freq_used = stats.get("freq_used", "D")
                    freq_icon = "üìÖ" if freq_used == "D" else "üìÜ"
                    st.metric("Aggregation Frequency", f"{freq_icon} {freq_used}")
                    
                    if agg_suggestion:
                        st.info(f"üí° Suggestion: {agg_suggestion.get('freq', 'D')} - {agg_suggestion.get('reason', '')}")
                
                if stats.get("warning"):
                    st.warning(f"‚ö†Ô∏è {stats['warning']}")
                
                # Show detailed stats
                with st.expander("üìã Detailed Statistics"):
                    st.json(stats)
            else:
                st.error(f"‚ùå Preprocessing failed: {response.text}")
        except Exception as e:
            st.error(f"‚ùå Error preprocessing data: {str(e)}")

# Train section
st.header("üéØ Step 3: Train Model")
if st.session_state.preprocessed_shop_csv:
    st.info(f"üìä Using shop data: {st.session_state.preprocessed_shop_csv}")
    
    # Show recommended settings for best results
    with st.expander("üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞", expanded=False):
        st.write("""
        **–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–ø–æ–∫–∞–∑–∞–ª–∏ MAPE ~39% –≤ —Ç–µ—Å—Ç–∞—Ö):**
        
        ‚úÖ **Model Configuration:**
        - Use regressors: ‚ùå –í–´–ö–õ–Æ–ß–ï–ù–û
        - Log-transform: ‚ùå –í–´–ö–õ–Æ–ß–ï–ù–û
        - Interval width: 0.95
        - Holdout fraction: 0.20
        
        ‚úÖ **Advanced Hyperparameters:**
        - Seasonality mode: **additive**
        - Changepoint flexibility: **0.01** (–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π)
        - Seasonality strength: **10.0** (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π)
        
        ‚ö†Ô∏è **–í–∞–∂–Ω–æ:** –ü–æ—Å–ª–µ –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö (Step 1) —ç—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–∞—é—Ç –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ!
        """)
    
    # Analyze data and provide recommendations
    try:
        df_preview = pd.read_csv(st.session_state.preprocessed_shop_csv)
        if 'y' in df_preview.columns:
            mean_sales = df_preview['y'].mean()
            std_sales = df_preview['y'].std()
            cv = std_sales / mean_sales if mean_sales > 0 else 0  # Coefficient of variation
            min_sales = df_preview['y'].min()
            max_sales = df_preview['y'].max()
            
            # Generate recommendations
            recommendations = []
            if cv > 1.0:  # High volatility
                recommendations.append("üî¥ –í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö (CV > 1.0) - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –≤–∫–ª—é—á–∏—Ç—å **log-transform**")
                recommendations.append("üî¥ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å **multiplicative** seasonality mode")
            elif cv > 0.5:
                recommendations.append("üü° –£–º–µ—Ä–µ–Ω–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å - –º–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å **log-transform**")
            
            if min_sales >= 0 and max_sales / mean_sales > 10:
                recommendations.append("üü° –ë–æ–ª—å—à–æ–π —Ä–∞–∑–±—Ä–æ—Å –∑–Ω–∞—á–µ–Ω–∏–π - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è **log-transform**")
            
            if recommendations:
                with st.expander("üí° –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö", expanded=True):
                    st.write("**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö:**")
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("–°—Ä–µ–¥–Ω–µ–µ", f"{mean_sales:.2f}")
                    with col2:
                        st.metric("–°—Ç–¥. –æ—Ç–∫–ª.", f"{std_sales:.2f}")
                    with col3:
                        st.metric("CV", f"{cv:.2f}")
                    with col4:
                        st.metric("Min/Max", f"{min_sales:.0f} / {max_sales:.0f}")
                    
                    st.write("**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**")
                    for rec in recommendations:
                        st.write(f"- {rec}")
    except Exception as e:
        pass  # Skip recommendations if data can't be loaded
    
    # Model configuration
    with st.expander("‚öôÔ∏è Model Configuration", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            include_regressors = st.checkbox(
                "Use regressors (price/discount)",
                value=False,
                help="Include average price and average discount as regressors in the Prophet model"
            )
            
            log_transform = st.checkbox(
                "Apply log-transform to target",
                value=False,
                help="‚ö†Ô∏è –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø –¥–ª—è –¥–∞–Ω–Ω—ã—Ö —Å –≤—ã—Å–æ–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å—é! Apply log1p transformation to target variable (useful for skewed data)"
            )
        
        with col2:
            interval_width = st.slider(
                "Interval width",
                min_value=0.5,
                max_value=0.99,
                value=0.95,
                step=0.01,
                help="Confidence interval width for predictions (0.95 = 95% confidence)"
            )
            
            holdout_frac = st.slider(
                "Holdout fraction",
                min_value=0.05,
                max_value=0.5,
                value=0.2,
                step=0.05,
                help="Fraction of data to use for testing (e.g., 0.2 = 20% for test set)"
            )
        
        # Skip holdout option (–¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–∞ –±—É–¥—É—â–µ–µ)
        skip_holdout = st.checkbox(
            "üöÄ Train on ALL data (skip holdout) - –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–∞ –±—É–¥—É—â–µ–µ",
            value=False,
            help="–ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ: –º–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –í–°–ï–• –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ train/test. "
                 "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–Ω-–ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–µ –±—É–¥—É—â–µ–µ (–Ω–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã–π –ø–µ—Ä–∏–æ–¥). "
                 "‚ö†Ô∏è –ú–µ—Ç—Ä–∏–∫–∏ (MAPE, MAE) –Ω–µ –±—É–¥—É—Ç –≤—ã—á–∏—Å–ª–µ–Ω—ã, —Ç–∞–∫ –∫–∞–∫ –Ω–µ—Ç —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞."
        )
        
        if skip_holdout:
            st.info("üí° **–†–µ–∂–∏–º –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–∞ –±—É–¥—É—â–µ–µ:** –ú–æ–¥–µ–ª—å –æ–±—É—á–∏—Ç—Å—è –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö. "
                   "–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–∞–∑–¥–µ–ª 'Generate Forecast' –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ –±—É–¥—É—â–∏–µ –¥–∞—Ç—ã. "
                   "Holdout fraction –±—É–¥–µ—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω.")
        
        # Advanced hyperparameters
        with st.expander("üîß Advanced Hyperparameters (–¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞)", expanded=False):
            # Warning about log_transform + multiplicative combination
            if log_transform:
                st.info("üí° **–°–æ–≤–µ—Ç**: –ü—Ä–∏ –≤–∫–ª—é—á–µ–Ω–Ω–æ–º log-transform –æ–±—ã—á–Ω–æ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å **additive** seasonality. Multiplicative + log-transform –º–æ–≥—É—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤–∞—Ç—å –∏ –¥–∞–≤–∞—Ç—å —Å–ª–∏—à–∫–æ–º —à–∏—Ä–æ–∫–∏–µ confidence intervals.")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                seasonality_mode = st.selectbox(
                    "Seasonality mode",
                    options=["additive", "multiplicative"],
                    index=0 if log_transform else 0,  # Suggest additive if log_transform is on
                    help="additive: —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∫ —Ç—Ä–µ–Ω–¥—É. multiplicative: —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å —É–º–Ω–æ–∂–∞–µ—Ç—Å—è –Ω–∞ —Ç—Ä–µ–Ω–¥ (–ª—É—á—à–µ –¥–ª—è –≤—ã—Å–æ–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏, –Ω–æ –ë–ï–ó log-transform)"
                )
            
            with col2:
                changepoint_prior_scale = st.slider(
                    "Changepoint flexibility",
                    min_value=0.001,
                    max_value=0.5,
                    value=0.01,
                    step=0.001,
                    format="%.3f",
                    help="–ì–∏–±–∫–æ—Å—Ç—å –¥–µ—Ç–µ–∫—Ü–∏–∏ —Ç–æ—á–µ–∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞ (–≤—ã—à–µ = –±–æ–ª—å—à–µ –≥–∏–±–∫–æ—Å—Ç–∏, —Ä–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è). –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: 0.005-0.01 –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
                )
            
            with col3:
                seasonality_prior_scale = st.slider(
                    "Seasonality strength",
                    min_value=0.01,
                    max_value=100.0,
                    value=10.0,
                    step=1.0,
                    help="–°–∏–ª–∞ —Å–µ–∑–æ–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ (–≤—ã—à–µ = —Å–∏–ª—å–Ω–µ–µ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å)"
                )
    
    col1, col2 = st.columns([1, 1])
    with col1:
        model_out_path = st.text_input(
            "Model output path",
            value="models/prophet_model.pkl",
            help="Path where the trained model will be saved"
        )
    
    # Auto-tune option
    auto_tune = st.checkbox(
        "üîç Auto-tune model (Grid Search)",
        value=False,
        help="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Ö–æ–¥–∏—Ç –ª—É—á—à—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ grid search (Prophet –≤–∞—Ä–∏–∞–Ω—Ç—ã, LSTM, Hybrid). –≠—Ç–æ –∑–∞–π–º–µ—Ç –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏, –Ω–æ –¥–∞—Å—Ç –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã."
    )
    
    if auto_tune:
        st.info("üí° –ü—Ä–∏ –≤–∫–ª—é—á–µ–Ω–Ω–æ–º auto-tune –±—É–¥—É—Ç –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Prophet, LSTM –∏ –≥–∏–±—Ä–∏–¥–Ω—ã–µ –º–æ–¥–µ–ª–∏. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—Ç—Å—è –≤ analysis/model_comparison.csv")
    
    if st.button("üöÄ Train Model", help="Trains a Prophet model with the selected configuration"):
        try:
            payload = {
                "shop_csv": st.session_state.preprocessed_shop_csv,
                "model_out": model_out_path,
                "include_regressors": include_regressors,
                "log_transform": log_transform,
                "interval_width": interval_width,
                "holdout_frac": holdout_frac,
                "changepoint_prior_scale": changepoint_prior_scale,
                "seasonality_prior_scale": seasonality_prior_scale,
                "seasonality_mode": seasonality_mode,
                "auto_tune": auto_tune,
                "skip_holdout": skip_holdout  # –ù–æ–≤—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä
            }
            
            spinner_text = "Training model with auto-tuning (this may take several minutes)..." if auto_tune else "Training model... This may take a while."
            timeout_val = 1800 if auto_tune else 300  # 30 minutes for auto-tune, 5 minutes for regular
            
            with st.spinner(spinner_text):
                response = requests.post(f"{FASTAPI_URL}/train", json=payload, timeout=timeout_val)
            
            if response.status_code == 200:
                result = response.json()
                st.session_state.trained_model_path = result["model_path"]
                st.session_state.training_metrics = result["metrics"]
                
                if skip_holdout:
                    st.success("‚úÖ Model trained successfully on ALL data! Ready for production forecasts.")
                    st.info("üí° **–†–µ–∂–∏–º –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–∞ –±—É–¥—É—â–µ–µ:** –ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ –≤—ã—á–∏—Å–ª–µ–Ω—ã (–Ω–µ—Ç —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞). "
                            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–∞–∑–¥–µ–ª 'Generate Forecast' –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ –±—É–¥—É—â–∏–µ –¥–∞—Ç—ã.")
                else:
                    st.success("‚úÖ Model trained successfully!")
                
                # Display metrics
                st.subheader("üìà Training Metrics")
                
                metrics = result["metrics"]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º skip_holdout
                if skip_holdout or metrics.get('mape') is None:
                    st.info("‚ÑπÔ∏è –ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ –≤—ã—á–∏—Å–ª–µ–Ω—ã: –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö (skip_holdout=True). "
                           "–ì–æ—Ç–æ–≤–∞ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–µ –±—É–¥—É—â–µ–µ!")
                else:
                    col1, col2, col3 = st.columns(3)
                    mape_val = metrics.get('mape')
                    mae_val = metrics.get('mae')
                    rmse_val = metrics.get('rmse')
                    
                    # Determine metric status
                    if isinstance(mape_val, (int, float)):
                        if mape_val > 50:
                            mape_delta = "‚ùå –ö—Ä–∏—Ç–∏—á–Ω–æ –ø–ª–æ—Ö–æ"
                            mape_color = "off"
                        elif mape_val > 30:
                            mape_delta = "‚ö†Ô∏è –ü–ª–æ—Ö–æ"
                            mape_color = "off"
                        elif mape_val > 20:
                            mape_delta = "üü° –£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ"
                            mape_color = "normal"
                        elif mape_val > 15:
                            mape_delta = "‚úÖ –•–æ—Ä–æ—à–æ"
                            mape_color = "normal"
                        else:
                            mape_delta = "‚úÖ –û—Ç–ª–∏—á–Ω–æ"
                            mape_color = "normal"
                    else:
                        mape_delta = None
                        mape_color = "normal"
                    
                    with col1:
                        st.metric("MAE", f"{mae_val:.2f}" if mae_val is not None else "N/A")
                    with col2:
                        st.metric("RMSE", f"{rmse_val:.2f}" if rmse_val is not None else "N/A")
                    with col3:
                        if mape_val is not None:
                            st.metric("MAPE", f"{mape_val:.2f}%", delta=mape_delta if isinstance(mape_val, (int, float)) else None)
                        else:
                            st.metric("MAPE", "N/A", delta="Production mode")
                    
                    # Show quality warnings and recommendations (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –º–µ—Ç—Ä–∏–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)
                    if isinstance(mape_val, (int, float)):
                        if mape_val > 50:
                            st.error(f"üö® –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ö–ê–ß–ï–°–¢–í–û: MAPE = {mape_val:.2f}% —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏–π! –ú–æ–¥–µ–ª—å –Ω–µ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é.")
                            
                            # Check current configuration
                            current_log = metrics.get('log_transform', False)
                            current_mode = metrics.get('seasonality_mode', 'additive')
                            
                            with st.expander("üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é"):
                                if current_log and current_mode == 'multiplicative':
                                    st.warning("""
                                    ‚ö†Ô∏è **–û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ñ–ª–∏–∫—Ç**: log-transform + multiplicative seasonality
                                    
                                    **–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–¥–∏–Ω –∏–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤:**
                                    
                                    **–í–∞—Ä–∏–∞–Ω—Ç –ê (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è):**
                                    - ‚úÖ Log-transform: –í–ö–õ–Æ–ß–ï–ù–û
                                    - ‚úÖ Seasonality mode: **ADDITIVE** (–≤–º–µ—Å—Ç–æ multiplicative)
                                    - ‚úÖ Seasonality strength: 15-20
                                    - ‚úÖ Changepoint flexibility: 0.10-0.15
                                    
                                    **–í–∞—Ä–∏–∞–Ω—Ç –ë:**
                                    - ‚ùå Log-transform: –í–´–ö–õ–Æ–ß–ï–ù–û  
                                    - ‚úÖ Seasonality mode: **MULTIPLICATIVE**
                                    - ‚úÖ Seasonality strength: 20-25
                                    - ‚úÖ Changepoint flexibility: 0.15-0.20
                                    """)
                                else:
                                    st.write("""
                                    **–ù–µ–º–µ–¥–ª–µ–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:**
                                    1. ‚úÖ –ï—Å–ª–∏ log-transform –í–´–ö–õ–Æ–ß–ï–ù - –≤–∫–ª—é—á–∏—Ç–µ –µ–≥–æ –ò –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ **additive** seasonality
                                    2. ‚úÖ –ï—Å–ª–∏ log-transform –í–ö–õ–Æ–ß–ï–ù - –ø–æ–ø—Ä–æ–±—É–π—Ç–µ **additive** –≤–º–µ—Å—Ç–æ multiplicative
                                    3. ‚úÖ –£–≤–µ–ª–∏—á—å—Ç–µ **seasonality_prior_scale** –¥–æ 20-25
                                    4. ‚úÖ –£–≤–µ–ª–∏—á—å—Ç–µ **changepoint_prior_scale** –¥–æ 0.15-0.20 (–±–æ–ª—å—à–µ –≥–∏–±–∫–æ—Å—Ç–∏)
                                    5. ‚úÖ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤–∫–ª—é—á–∏—Ç—å **regressors** (price/discount)
                                    6. ‚ö†Ô∏è –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –≤—ã–±—Ä–æ—Å—ã –∏ –∞–Ω–æ–º–∞–ª–∏–∏
                                    
                                    **–¶–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:**
                                    - MAPE < 15-20% –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞
                                    - –¢–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–æ –¥–ª—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                                    """)
                        elif mape_val > 30:
                            st.warning(f"‚ö†Ô∏è –ö–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ –Ω–∏–∂–µ —Å—Ä–µ–¥–Ω–µ–≥–æ: MAPE = {mape_val:.2f}%. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–ª—É—á—à–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.")
                            
                            current_log = metrics.get('log_transform', False)
                            current_mode = metrics.get('seasonality_mode', 'additive')
                            
                            with st.expander("üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é"):
                                if current_log and current_mode == 'multiplicative':
                                    st.write("""
                                    ‚ö†Ô∏è **–°–æ–≤–µ—Ç**: Log-transform + multiplicative –º–æ–≥—É—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤–∞—Ç—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ:
                                    1. –û—Å—Ç–∞–≤–∏—Ç—å log-transform, –∏–∑–º–µ–Ω–∏—Ç—å –Ω–∞ **additive** seasonality
                                    2. –ò–ª–∏ –≤—ã–∫–ª—é—á–∏—Ç—å log-transform, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å **multiplicative**
                                    3. –£–≤–µ–ª–∏—á–∏—Ç—å **changepoint_prior_scale** –¥–æ 0.12-0.15
                                    """)
                                else:
                                    st.write("""
                                    **–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:**
                                    1. –ï—Å–ª–∏ log-transform –≤—ã–∫–ª—é—á–µ–Ω - –≤–∫–ª—é—á–∏—Ç–µ –µ–≥–æ (—Å additive)
                                    2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ **changepoint_prior_scale** (0.10-0.15) –∏ **seasonality_prior_scale** (20-25)
                                    3. –ü—Ä–æ–≤–µ–¥–∏—Ç–µ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                                    """)
                        elif mape_val > 20:
                            st.info(f"‚ÑπÔ∏è –ö–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ: MAPE = {mape_val:.2f}%. –ú–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —É–ª—É—á—à–∏—Ç—å –¥–ª—è –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.")
                        elif mape_val <= 15:
                            st.success(f"‚úÖ –û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏! MAPE = {mape_val:.2f}% - –º–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É.")
                
                # Show training info
                with st.expander("üìä Training Details"):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write("**Training Period:**")
                        st.write(f"- Start: {result['train_range']['start'][:10]}")
                        st.write(f"- End: {result['train_range']['end'][:10]}")
                        st.write(f"- Samples: {result['n_train']}")
                    
                    with col2:
                        if skip_holdout or result.get('test_range', {}).get('start') is None:
                            st.write("**‚ö†Ô∏è Production Mode:**")
                            st.write("- Test Period: N/A (skip_holdout=True)")
                            st.write("- Samples in test: 0")
                            st.info("üí° –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö. –ì–æ—Ç–æ–≤–∞ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–µ –±—É–¥—É—â–µ–µ!")
                        else:
                            st.write("**Test Period:**")
                            test_start = result.get('test_range', {}).get('start', 'N/A')
                            test_end = result.get('test_range', {}).get('end', 'N/A')
                            if test_start and test_start != 'N/A':
                                st.write(f"- Start: {test_start[:10] if isinstance(test_start, str) else test_start}")
                            if test_end and test_end != 'N/A':
                                st.write(f"- End: {test_end[:10] if isinstance(test_end, str) else test_end}")
                            st.write(f"- Samples: {result.get('n_test', 0)}")
                    
                    st.write("**Configuration:**")
                    st.write(f"- Log transform: {metrics.get('log_transform', False)}")
                    st.write(f"- Interval width: {metrics.get('interval_width', 0.95)}")
                    st.write(f"- Seasonality mode: {metrics.get('seasonality_mode', 'additive')}")
                    st.write(f"- Changepoint prior scale: {metrics.get('changepoint_prior_scale', 0.05)}")
                    st.write(f"- Seasonality prior scale: {metrics.get('seasonality_prior_scale', 10.0)}")
                    st.write(f"- Used cross-validation: {metrics.get('used_cross_validation', False)}")
                    st.write(f"- Auto-tune used: {metrics.get('auto_tune', False)}")
                
                # Show auto-tune results if available (–ø—Ä–æ–≤–µ—Ä—è–µ–º skip_holdout —á–µ—Ä–µ–∑ metrics)
                if response.status_code == 200 and metrics.get('auto_tune', False):
                    try:
                        import os
                        comparison_csv = "analysis/model_comparison.csv"
                        if os.path.exists(comparison_csv):
                            df_comparison = pd.read_csv(comparison_csv)
                            st.subheader("üìä Model Comparison (Auto-tune Results)")
                            
                            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ MAPE
                            df_comparison_sorted = df_comparison.sort_values('mape')
                            st.dataframe(df_comparison_sorted, use_container_width=True)
                            
                            # Plot comparison —Å —Ü–≤–µ—Ç–æ–≤–æ–π –∏–Ω–¥–∏–∫–∞—Ü–∏–µ–π –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
                            fig_comparison = go.Figure()
                            
                            # –¶–≤–µ—Ç–∞: –∑–µ–ª–µ–Ω—ã–π –¥–ª—è –ª—É—á—à–µ–π, —Å–∏–Ω–∏–π –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö
                            colors = ['green' if i == 0 else 'lightblue' for i in range(len(df_comparison_sorted))]
                            
                            fig_comparison.add_trace(go.Bar(
                                x=df_comparison_sorted['model_name'],
                                y=df_comparison_sorted['mape'],
                                name='MAPE (%)',
                                marker_color=colors,
                                text=[f"{m:.1f}%" for m in df_comparison_sorted['mape']],
                                textposition='outside',
                                hovertemplate='<b>%{x}</b><br>MAPE: %{y:.2f}%<br>Coverage: %{customdata:.1f}%<extra></extra>',
                                customdata=df_comparison_sorted['coverage'] * 100
                            ))
                            fig_comparison.update_layout(
                                title="MAPE Comparison Across Models (Green = Best Model)",
                                xaxis_title="Model",
                                yaxis_title="MAPE (%)",
                                height=500,
                                showlegend=False
                            )
                            st.plotly_chart(fig_comparison, use_container_width=True)
                            
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤ session state
                            st.session_state.model_comparison = df_comparison_sorted
                            
                            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
                            best_model_name = df_comparison_sorted.iloc[0]['model_name']
                            best_mape = df_comparison_sorted.iloc[0]['mape']
                            best_coverage = df_comparison_sorted.iloc[0]['coverage'] * 100
                            
                            st.success(f"üèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: **{best_model_name}** (MAPE: {best_mape:.2f}%, Coverage: {best_coverage:.1f}%)")
                            st.info(f"üí° –¢–µ–∫—É—â–∏–π –ø—Ä–æ–≥–Ω–æ–∑ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ –ø—É—Ç–∏: {model_out_path}. "
                                   f"–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥—Ä—É–≥–æ–π –º–æ–¥–µ–ª–∏ –∏–∑ —Å–ø–∏—Å–∫–∞ –ø–µ—Ä–µ–æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –≤—Ä—É—á–Ω—É—é.")
                    except Exception as e:
                        st.warning(f"Could not load auto-tune comparison results: {str(e)}")
            else:
                st.error(f"‚ùå Training failed: {response.text}")
        except Exception as e:
            st.error(f"‚ùå Error training model: {str(e)}")
    
    # Diagnostics section
    if st.session_state.trained_model_path and st.session_state.preprocessed_shop_csv:
        st.subheader("üîç Model Diagnostics")
        
        col1, col2 = st.columns([2, 1])
        with col1:
            st.info("–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–∏ –ø–æ–º–æ–∂–µ—Ç –≤—ã—è–≤–∏—Ç—å —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã: –ø–µ—Ä–µ–æ—Ü–µ–Ω–∫–∞ —Ç—Ä–µ–Ω–¥–∞, –Ω–∏–∑–∫–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ CI, —Å–º–µ—â–µ–Ω–∏–µ –º–∏–Ω–∏–º—É–º–æ–≤ –∏ –¥—Ä.")
        with col2:
            if st.button("üîç Run Diagnostics", help="–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—É—é –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É –º–æ–¥–µ–ª–∏"):
                try:
                    # –ü–æ–ª—É—á–∞–µ–º include_regressors –∏–∑ –º–µ—Ç—Ä–∏–∫, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
                    include_regressors_diag = False
                    if st.session_state.training_metrics:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å –ª–∏ —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä—ã (–º–æ–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —á–µ—Ä–µ–∑ –Ω–∞–ª–∏—á–∏–µ avg_price –≤ –¥–∞–Ω–Ω—ã—Ö)
                        try:
                            df_check = pd.read_csv(st.session_state.preprocessed_shop_csv)
                            include_regressors_diag = 'avg_price' in df_check.columns
                        except:
                            pass
                    
                    payload = {
                        "shop_csv": st.session_state.preprocessed_shop_csv,
                        "model_path": st.session_state.trained_model_path,
                        "include_regressors": include_regressors_diag
                    }
                    
                    with st.spinner("Running diagnostics..."):
                        response = requests.post(f"{FASTAPI_URL}/diagnose", json=payload, timeout=120)
                    
                    if response.status_code == 200:
                        diagnostics = response.json()
                        st.session_state.diagnostics = diagnostics
                        
                        st.success("‚úÖ Diagnostics completed!")
                        
                        # Display diagnostics
                        st.subheader("üìä Diagnostic Results")
                        
                        metrics_diag = diagnostics.get('metrics', {})
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("MAPE", f"{metrics_diag.get('mape', 0):.2f}%")
                        with col2:
                            st.metric("Systematic Bias", f"{metrics_diag.get('systematic_bias', 0):.2f}")
                        with col3:
                            coverage = diagnostics.get('coverage', {}).get('coverage_rate', 0) * 100
                            st.metric("CI Coverage", f"{coverage:.1f}%")
                        
                        # Trend bias
                        trend_bias = diagnostics.get('trend_bias', {})
                        if trend_bias.get('has_bias', False):
                            st.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–º–µ—â–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞: {trend_bias.get('trend_bias_pct', 0):.1f}%")
                        else:
                            st.success("‚úÖ –°–º–µ—â–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
                        
                        # Coverage warning
                        if coverage < 85:
                            st.warning(f"‚ö†Ô∏è –ü–æ–∫—Ä—ã—Ç–∏–µ CI —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–æ–µ ({coverage:.1f}%). –ñ–µ–ª–∞—Ç–µ–ª—å–Ω–æ >= 85%")
                        
                        # Residuals analysis
                        residuals = diagnostics.get('residuals_analysis', {})
                        with st.expander("üìà Residuals Analysis"):
                            st.write(f"Mean residual: {residuals.get('mean', 0):.2f}")
                            st.write(f"Std residual: {residuals.get('std', 0):.2f}")
                            st.write(f"Normality test p-value: {residuals.get('normality_test_pvalue', 0):.4f}")
                            if residuals.get('has_trend', False):
                                st.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω —Ç—Ä–µ–Ω–¥ –≤ –æ—Å—Ç–∞—Ç–∫–∞—Ö: slope={residuals.get('trend_slope', 0):.6f}")
                        
                        # Multicollinearity
                        multicollinearity = diagnostics.get('multicollinearity', {})
                        if multicollinearity.get('has_multicollinearity', False):
                            st.error("üö® –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä–æ–≤!")
                            st.write(f"Max correlation: {multicollinearity.get('max_correlation', 0):.2f}")
                            st.write(f"VIF scores: {multicollinearity.get('vif_scores', {})}")
                        
                        # Minima shift
                        minima_shift = diagnostics.get('minima_shift', {})
                        mean_shift = minima_shift.get('mean_shift_days', 0)
                        if abs(mean_shift) > 3:
                            st.warning(f"‚ö†Ô∏è –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–∏–Ω–∏–º—É–º—ã —Å–¥–≤–∏–Ω—É—Ç—ã –Ω–∞ {mean_shift:.1f} –¥–Ω–µ–π")
                        
                    else:
                        st.error(f"‚ùå Diagnostics failed: {response.text}")
                except Exception as e:
                    st.error(f"‚ùå Error running diagnostics: {str(e)}")

# Evaluate section
st.header("üìä Step 4: Evaluate Model (Cross-Validation)")
if st.session_state.preprocessed_shop_csv:
    with st.expander("üîç Cross-Validation Configuration", expanded=False):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            initial_days = st.number_input(
                "Initial training days",
                min_value=30,
                value=180,
                step=30,
                help="Number of days for initial training period in rolling CV"
            )
        
        with col2:
            horizon_days = st.number_input(
                "Forecast horizon (days)",
                min_value=1,
                value=30,
                step=5,
                help="Number of days to forecast ahead in each CV step"
            )
        
        with col3:
            period_days = st.number_input(
                "Window slide period (days)",
                min_value=1,
                value=30,
                step=5,
                help="Number of days to slide the window forward between CV steps"
            )
        
        cv_include_regressors = st.checkbox(
            "Use regressors for CV",
            value=False,
            help="Include regressors in cross-validation (must match training configuration)"
        )
        
        cv_log_transform = st.checkbox(
            "Apply log-transform for CV",
            value=False,
            help="Apply log-transform in cross-validation (must match training configuration)"
        )
    
    if st.button("üìà Run Cross-Validation", help="Performs rolling cross-validation to evaluate model performance"):
        try:
            payload = {
                "shop_csv": st.session_state.preprocessed_shop_csv,
                "initial_days": initial_days,
                "horizon_days": horizon_days,
                "period_days": period_days,
                "include_regressors": cv_include_regressors,
                "log_transform": cv_log_transform
            }
            
            with st.spinner("Running cross-validation... This may take several minutes."):
                response = requests.post(f"{FASTAPI_URL}/evaluate", json=payload, timeout=600)
            
            if response.status_code == 200:
                result = response.json()
                st.session_state.cv_results = result
                
                st.success("‚úÖ Cross-validation completed!")
                
                # Display aggregate metrics
                st.subheader("üìä Cross-Validation Results")
                
                metrics = result["metrics"]
                summary = result["summary"]
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("MAE", f"{summary['mae_mean']:.2f}", f"¬±{summary['mae_std']:.2f}")
                with col2:
                    st.metric("RMSE", f"{summary['rmse_mean']:.2f}", f"¬±{summary['rmse_std']:.2f}")
                with col3:
                    st.metric("MAPE", f"{summary['mape_mean']:.2f}%", f"¬±{summary['mape_std']:.2f}%")
                
                st.info(f"üìä Number of CV steps: {result['n_cv_steps']}")
                st.info(f"üíæ Predictions saved to: {result['cv_predictions_csv']}")
                
                # Plot CV results
                try:
                    df_cv = pd.read_csv(result['cv_predictions_csv'])
                    df_cv['ds'] = pd.to_datetime(df_cv['ds'])
                    df_cv = df_cv.sort_values('ds')
                    
                    fig = go.Figure()
                    
                    # Plot actual
                    fig.add_trace(go.Scatter(
                        x=df_cv['ds'],
                        y=df_cv['actual'],
                        mode='lines+markers',
                        name='Actual Sales',
                        line=dict(color='blue', width=2),
                        marker=dict(size=4)
                    ))
                    
                    # Plot predictions (grouped by CV step)
                    if 'cv_step' in df_cv.columns:
                        for step in sorted(df_cv['cv_step'].unique()):
                            step_data = df_cv[df_cv['cv_step'] == step]
                            fig.add_trace(go.Scatter(
                                x=step_data['ds'],
                                y=step_data['predicted'],
                                mode='lines+markers',
                                name=f'Predictions (Step {step})',
                                line=dict(color='red', width=1, dash='dash'),
                                marker=dict(size=3)
                            ))
                    else:
                        fig.add_trace(go.Scatter(
                            x=df_cv['ds'],
                            y=df_cv['predicted'],
                            mode='lines+markers',
                            name='Predictions',
                            line=dict(color='red', width=1, dash='dash'),
                            marker=dict(size=3)
                        ))
                    
                    fig.update_layout(
                        title="Cross-Validation Results: Actual vs Predicted",
                        xaxis_title="Date",
                        yaxis_title="Sales",
                        hovermode='x unified',
                        height=500,
                        showlegend=True
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.warning(f"Could not plot CV results: {str(e)}")
                
            else:
                st.error(f"‚ùå Cross-validation failed: {response.text}")
        except Exception as e:
            st.error(f"‚ùå Error running cross-validation: {str(e)}")

# Predict section
st.header("üîÆ Step 5: Generate Forecast")
st.info("üí° **–ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –±—É–¥—É—â–µ–µ:** –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞ —Å 'skip_holdout=True', –ø—Ä–æ–≥–Ω–æ–∑ –±—É–¥–µ—Ç —Å–¥–µ–ª–∞–Ω –Ω–∞ –¥–∞—Ç—ã **–ø–æ—Å–ª–µ** –ø–æ—Å–ª–µ–¥–Ω–µ–π –¥–∞—Ç—ã –≤ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö. "
       "–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ —É–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ `.pkl` —Ñ–∞–π–ª—É –Ω–∏–∂–µ.")

if st.session_state.trained_model_path:
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏
    model_info = f"ü§ñ Using model: `{st.session_state.trained_model_path}`"
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ —Å skip_holdout
    if st.session_state.training_metrics and st.session_state.training_metrics.get('skip_holdout', False):
        st.success("‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö - –≥–æ—Ç–æ–≤–∞ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–µ –±—É–¥—É—â–µ–µ!")
else:
    # –ü–æ–∑–≤–æ–ª—è–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –≤—Ä—É—á–Ω—É—é
    st.subheader("üìÇ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –æ—Ç–¥–µ–ª—å–Ω–æ, —á—Ç–æ–±—ã –Ω–µ —Å–±—Ä–∞—Å—ã–≤–∞–ª—Å—è –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞
    if 'saved_model_path' not in st.session_state:
        st.session_state.saved_model_path = ""
    
    saved_model_path = st.text_input(
        "–ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (.pkl)",
        value=st.session_state.saved_model_path,
        help="–£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ —Ä–∞–Ω–µ–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –±–µ–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è"
    )
    
    if saved_model_path and saved_model_path.endswith('.pkl'):
        import os
        if os.path.exists(saved_model_path):
            st.session_state.trained_model_path = saved_model_path
            st.session_state.saved_model_path = saved_model_path  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ session_state
            st.success(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {saved_model_path}")
            model_info = f"ü§ñ Using saved model: `{saved_model_path}`"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ç—Ä–µ–±—É–µ—Ç –ª–∏ –º–æ–¥–µ–ª—å —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä—ã
            try:
                import joblib
                model = joblib.load(saved_model_path)
                requires_regressors = len(model.extra_regressors) > 0 if hasattr(model, 'extra_regressors') else False
                if requires_regressors:
                    st.warning("‚ö†Ô∏è **–ú–æ–¥–µ–ª—å —Ç—Ä–µ–±—É–µ—Ç —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä—ã** (avg_price, avg_discount). –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ CSV —Å —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä–∞–º–∏ –Ω–∏–∂–µ.")
            except Exception as e:
                pass  # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –º–æ–¥–µ–ª—å, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
        else:
            st.error(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {saved_model_path}")
            st.stop()
    elif saved_model_path:
        st.warning("‚ö†Ô∏è –ü—É—Ç—å –¥–æ–ª–∂–µ–Ω —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ —Ñ–∞–π–ª .pkl")
        st.stop()

if st.session_state.trained_model_path:
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π
    if 'model_comparison' in st.session_state and st.session_state.model_comparison is not None:
        df_comp = st.session_state.model_comparison
        # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –∫–∞–∫–∞—è –º–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ –ø—É—Ç–∏
        model_name_from_path = os.path.basename(st.session_state.trained_model_path).replace('.pkl', '')
        
        # –ò—â–µ–º –º–µ—Ç—Ä–∏–∫–∏ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏
        matching_models = df_comp[df_comp['model_name'].str.contains(model_name_from_path, case=False, na=False)]
        if len(matching_models) == 0:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
            best_model = df_comp.iloc[0]
            model_info += f"\n\nüìä **–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –∏–∑ auto-tune**: {best_model['model_name']} "
            model_info += f"(MAPE: {best_model['mape']:.2f}%, Coverage: {best_model['coverage']*100:.1f}%)"
        else:
            current_model = matching_models.iloc[0]
            model_info += f"\n\nüìä **–ú–µ—Ç—Ä–∏–∫–∏ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏**: MAPE: {current_model['mape']:.2f}%, "
            model_info += f"Coverage: {current_model['coverage']*100:.1f}%"
    else:
        # –ï—Å–ª–∏ –µ—Å—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Ö
        if st.session_state.training_metrics:
            mape_val = st.session_state.training_metrics.get('mape', 'N/A')
            model_info += f"\nüìä MAPE: {mape_val:.2f}%" if isinstance(mape_val, (int, float)) else ""
    
    st.info(model_info)
    
    col1, col2 = st.columns(2)
    
    with col1:
        horizon = st.number_input(
            "Forecast horizon (days)",
            min_value=1,
            max_value=365,
            value=30,
            step=1,
            help="Number of days to forecast into the future"
        )
        
        log_transform_predict = st.checkbox(
            "Apply log-transform (inverse)",
            value=st.session_state.training_metrics.get('log_transform', False) if st.session_state.training_metrics else False,
            help="Apply inverse log1p transformation to predictions (should match training setting)"
        )
        
        smooth_transition = st.checkbox(
            "‚ö†Ô∏è Smooth transition (–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø: —É–º–µ–Ω—å—à–∞–µ—Ç –∑–∞–≤—ã—à–µ–Ω–∏–µ –≤ –Ω–∞—á–∞–ª–µ)",
            value=True,
            help="–ü—Ä–∏–º–µ–Ω—è–µ—Ç –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –ø–µ—Ä–≤—ã—Ö –¥–Ω–µ–π –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –∑–∞–≤—ã—à–µ–Ω–∏—è. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∫–∞–∫ —è–∫–æ—Ä—å."
        )
        
        if not smooth_transition:
            st.warning("‚ö†Ô∏è –ë–µ–∑ smooth transition –ø—Ä–æ–≥–Ω–æ–∑ –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞–≤—ã—à–µ–Ω –≤ –Ω–∞—á–∞–ª–µ –ø–µ—Ä–∏–æ–¥–∞!")
    
    with col2:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ç—Ä–µ–±—É–µ—Ç –ª–∏ –º–æ–¥–µ–ª—å —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä—ã
        model_requires_regressors = False
        regressors_csv_value = st.session_state.preprocessed_shop_csv if st.session_state.preprocessed_shop_csv else ""
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å, –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ—ë
        if st.session_state.trained_model_path:
            try:
                import joblib
                import os
                if os.path.exists(st.session_state.trained_model_path):
                    model = joblib.load(st.session_state.trained_model_path)
                    model_requires_regressors = len(model.extra_regressors) > 0 if hasattr(model, 'extra_regressors') else False
            except Exception:
                pass  # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
        
        regressor_strategy = st.selectbox(
            "Regressor fill strategy",
            options=["ffill", "median"],
            help="Strategy for filling regressors on future dates: 'ffill' uses last known values, 'median' uses median",
            disabled=not model_requires_regressors  # –û—Ç–∫–ª—é—á–∞–µ–º, –µ—Å–ª–∏ —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä—ã –Ω–µ –Ω—É–∂–Ω—ã
        )
        
        regressors_csv = st.text_input(
            "Regressors CSV (optional)",
            value=regressors_csv_value,
            help="Path to CSV with regressors (avg_price, avg_discount). –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä—ã!",
            disabled=not model_requires_regressors  # –û—Ç–∫–ª—é—á–∞–µ–º, –µ—Å–ª–∏ —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä—ã –Ω–µ –Ω—É–∂–Ω—ã
        )
        
        if model_requires_regressors:
            if not regressors_csv:
                st.error("‚ùå **–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ**: –ú–æ–¥–µ–ª—å —Ç—Ä–µ–±—É–µ—Ç —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä—ã! –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ avg_price –∏ avg_discount.")
            else:
                import os
                if not os.path.exists(regressors_csv):
                    st.error(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {regressors_csv}")
                else:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
                    try:
                        import pandas as pd
                        df_check = pd.read_csv(regressors_csv)
                        if 'avg_price' not in df_check.columns or 'avg_discount' not in df_check.columns:
                            st.warning("‚ö†Ô∏è CSV —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–ª–æ–Ω–æ–∫ avg_price –∏/–∏–ª–∏ avg_discount!")
                        else:
                            st.success("‚úÖ CSV —Å —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä–∞–º–∏ –Ω–∞–π–¥–µ–Ω")
                    except Exception as e:
                        st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å CSV: {str(e)}")
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è (–ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
    if smooth_transition:
        with st.expander("üîß –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è", expanded=False):
            smooth_days = st.slider(
                "–î–Ω–µ–π –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è",
                min_value=1,
                max_value=30,
                value=21,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 21 –¥–Ω—è –¥–ª—è –±–æ–ª–µ–µ –ø–ª–∞–≤–Ω–æ–≥–æ –ø–µ—Ä–µ—Ö–æ–¥–∞
                step=1,
                help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–≤—ã—Ö –¥–Ω–µ–π –ø—Ä–æ–≥–Ω–æ–∑–∞, –∫ –∫–æ—Ç–æ—Ä—ã–º –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 21-30)"
            )
            smooth_alpha = st.slider(
                "–í–µ—Å –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –¥–Ω—è (alpha)",
                min_value=0.0,
                max_value=1.0,
                value=0.6,  # UI –∑–Ω–∞—á–µ–Ω–∏–µ, –Ω–æ –≤ –∫–æ–¥–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ 0.95
                step=0.05,
                format="%.2f",
                disabled=True,  # –û—Ç–∫–ª—é—á–∞–µ–º - —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ 95%
                help="‚ö†Ô∏è –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 95% –≤–µ—Å–∞ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –¥–Ω—è (—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏)"
            )
            st.info("üí° –ü–µ—Ä–≤—ã–π –¥–µ–Ω—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç 95% –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è + 5% –ø—Ä–æ–≥–Ω–æ–∑–∞")
            max_change_pct = st.slider(
                "–ú–∞–∫—Å. –∏–∑–º–µ–Ω–µ–Ω–∏–µ –¥–µ–Ω—å-–¥–µ–Ω—å (%)",
                min_value=0.5,
                max_value=5.0,
                value=1.0,  # –°–Ω–∏–∂–µ–Ω–æ –¥–æ 1% –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                step=0.1,
                format="%.1f",
                help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –º–µ–∂–¥—É –¥–Ω—è–º–∏ (1% = –æ—á–µ–Ω—å –ø–ª–∞–≤–Ω—ã–π). –ü–µ—Ä–≤—ã–µ 3 –¥–Ω—è: 0.5%, –¥–Ω–∏ 4-7: 1%"
            )
    else:
        smooth_days = 14
        smooth_alpha = 0.6
        max_change_pct = 0.015
    
    if st.button("üîÆ Generate Forecast", help="Generates forecast for the specified horizon"):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ç—Ä–µ–±—É–µ—Ç –ª–∏ –º–æ–¥–µ–ª—å —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä—ã –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –∑–∞–ø—Ä–æ—Å–∞
        if model_requires_regressors and not regressors_csv:
            st.error("‚ùå **–û—à–∏–±–∫–∞**: –ú–æ–¥–µ–ª—å —Ç—Ä–µ–±—É–µ—Ç —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä—ã, –Ω–æ CSV —Ñ–∞–π–ª –Ω–µ —É–∫–∞–∑–∞–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ CSV —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ avg_price –∏ avg_discount.")
            st.stop()
        
        if model_requires_regressors and regressors_csv:
            import os
            if not os.path.exists(regressors_csv):
                st.error(f"‚ùå **–û—à–∏–±–∫–∞**: –§–∞–π–ª —Å —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {regressors_csv}")
                st.stop()
        
        try:
            payload = {
                "model_path": st.session_state.trained_model_path,
                "horizon": int(horizon),
                "log_transform": log_transform_predict,
                "future_regressor_strategy": regressor_strategy,
                "last_known_regressors_csv": regressors_csv if (regressors_csv and model_requires_regressors) else None,
                "smooth_transition": smooth_transition,
                "smooth_days": smooth_days,
                "smooth_alpha": smooth_alpha,
                "max_change_pct": max_change_pct / 100.0
            }
            
            with st.spinner("Generating forecast..."):
                response = requests.post(f"{FASTAPI_URL}/predict", json=payload, timeout=120)
            
            if response.status_code == 200:
                result = response.json()
                st.session_state.forecast_data = result["forecast"]
                st.session_state.forecast_csv_path = result["forecast_csv_path"]
                st.session_state.log_transform_used = log_transform_predict
                st.success(f"‚úÖ Forecast generated successfully! ({result['n_predictions']} predictions)")
            else:
                st.error(f"‚ùå Prediction failed: {response.text}")
        except Exception as e:
            st.error(f"‚ùå Error generating forecast: {str(e)}")
    
    # Display forecast visualization and table if forecast data exists
    if st.session_state.forecast_data is not None and st.session_state.forecast_csv_path is not None:
        # Load forecast data
        df_forecast = pd.DataFrame(st.session_state.forecast_data)
        df_forecast['ds'] = pd.to_datetime(df_forecast['ds'])
        
        # Ensure non-negative values (safety check for visualization)
        if 'yhat' in df_forecast.columns:
            n_neg = (df_forecast['yhat'] < 0).sum()
            if n_neg > 0:
                st.warning(f"‚ö†Ô∏è Found {n_neg} negative forecast values, clamping to 0")
                df_forecast['yhat'] = df_forecast['yhat'].clip(lower=0.0)
        
        if 'yhat_lower' in df_forecast.columns:
            n_neg = (df_forecast['yhat_lower'] < 0).sum()
            if n_neg > 0:
                st.warning(f"‚ö†Ô∏è Found {n_neg} negative lower bounds, clamping to 0")
                df_forecast['yhat_lower'] = df_forecast['yhat_lower'].clip(lower=0.0)
        
        if 'yhat_upper' in df_forecast.columns:
            n_neg = (df_forecast['yhat_upper'] < 0).sum()
            if n_neg > 0:
                st.warning(f"‚ö†Ô∏è Found {n_neg} negative upper bounds, clamping to 0")
                df_forecast['yhat_upper'] = df_forecast['yhat_upper'].clip(lower=0.0)
        
        # Ensure yhat_upper >= yhat_lower
        if 'yhat_lower' in df_forecast.columns and 'yhat_upper' in df_forecast.columns:
            df_forecast['yhat_upper'] = df_forecast[['yhat_upper', 'yhat_lower']].max(axis=1)
        
        # Plot forecast
        st.subheader("üìà Forecast Visualization")
        
        # Load history if available
        df_history = None
        train_end_date = None
        
        # Try to get training range from session state (stored after training)
        if 'training_metrics' in st.session_state and st.session_state.training_metrics:
            try:
                # Check if train_range is stored in metrics response
                # We need to get it from the training response, but for now use forecast start date
                forecast_start = df_forecast['ds'].min()
                # Assume training ended 1 day before forecast starts (typical case)
                train_end_date = forecast_start - pd.Timedelta(days=1)
            except:
                pass
        
        if st.session_state.preprocessed_shop_csv:
            try:
                df_history = pd.read_csv(st.session_state.preprocessed_shop_csv)
                df_history['ds'] = pd.to_datetime(df_history['ds'])
                df_history = df_history.sort_values('ds')
                
                # If we know training end date, split history into train/test periods
                if train_end_date is not None:
                    df_history_train = df_history[df_history['ds'] <= train_end_date].copy()
                    df_history_test = df_history[df_history['ds'] > train_end_date].copy()
                else:
                    # Use forecast start date as approximation
                    forecast_start = df_forecast['ds'].min()
                    df_history_train = df_history[df_history['ds'] < forecast_start].copy()
                    df_history_test = df_history[df_history['ds'] >= forecast_start].copy()
            except:
                df_history_train = None
                df_history_test = None
        else:
            df_history_train = None
            df_history_test = None
        
        fig = go.Figure()
        
        # Plot training period data
        if df_history_train is not None and not df_history_train.empty:
            fig.add_trace(go.Scatter(
                x=df_history_train['ds'],
                y=df_history_train['y'],
                mode='lines',
                name='Historical Sales (Training Period)',
                line=dict(color='blue', width=2)
            ))
        
        # Plot test period data (if available) - —ç—Ç–æ —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        if df_history_test is not None and not df_history_test.empty:
            fig.add_trace(go.Scatter(
                x=df_history_test['ds'],
                y=df_history_test['y'],
                mode='lines',
                name='Actual Sales (Test Period)',
                line=dict(color='green', width=2, dash='dash')
            ))
        
        # Plot forecast (future predictions)
        fig.add_trace(go.Scatter(
            x=df_forecast['ds'],
            y=df_forecast['yhat'],
            mode='lines',
            name='Forecast (Future)',
            line=dict(color='red', width=2)
        ))
        
        # Plot confidence intervals
        if 'yhat_lower' in df_forecast.columns and 'yhat_upper' in df_forecast.columns:
            fig.add_trace(go.Scatter(
                x=df_forecast['ds'],
                y=df_forecast['yhat_upper'],
                mode='lines',
                line=dict(width=0),
                showlegend=False,
                hoverinfo='skip'
            ))
            fig.add_trace(go.Scatter(
                x=df_forecast['ds'],
                y=df_forecast['yhat_lower'],
                mode='lines',
                line=dict(width=0),
                fill='tonexty',
                fillcolor='rgba(255, 0, 0, 0.2)',
                name='Confidence Interval',
                showlegend=True,
                hoverinfo='skip'
            ))
        
        title = "Sales Forecast"
        if st.session_state.get('log_transform_used', False):
            title += " (Log Transform Applied)"
        
        fig.update_layout(
            title=title,
            xaxis_title="Date",
            yaxis_title="Sales",
            hovermode='x unified',
            height=500,
            showlegend=True
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Display forecast table
        st.subheader("üìã Forecast Table")
        st.dataframe(df_forecast, use_container_width=True)
        
        # Download PDF section
        st.subheader("üì• Download PDF Report")
        
        # Button to generate PDF
        if st.button("üì• Generate PDF Report", help="Generates a PDF report with forecast visualization and statistics"):
            try:
                params = {"path": st.session_state.forecast_csv_path}
                with st.spinner("Generating PDF report..."):
                    response = requests.get(f"{FASTAPI_URL}/forecast/download", params=params, timeout=120)
                
                if response.status_code == 200:
                    st.session_state.pdf_data = response.content
                    st.session_state.pdf_filename = "forecast_report.pdf"
                    st.success("‚úÖ PDF report generated! Click the download button below.")
                else:
                    st.error(f"‚ùå PDF generation failed: {response.text}")
                    st.session_state.pdf_data = None
                    st.session_state.pdf_filename = None
            except Exception as e:
                st.error(f"‚ùå Error generating PDF: {str(e)}")
                st.session_state.pdf_data = None
                st.session_state.pdf_filename = None
        
        # Show download button if PDF data is available
        if st.session_state.pdf_data is not None:
            st.download_button(
                label="üíæ Download PDF",
                data=st.session_state.pdf_data,
                file_name=st.session_state.pdf_filename,
                mime="application/pdf",
                key='download_pdf'
            )
